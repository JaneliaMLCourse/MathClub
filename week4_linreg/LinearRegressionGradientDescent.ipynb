{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.set_printoptions(precision=2, floatmode='fixed', suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll solve the system with gradient descent!\n",
    "\n",
    "Check out [this blog post](https://towardsdatascience.com/linear-regression-using-gradient-descent-in-10-lines-of-code-642f995339c0)\n",
    "\n",
    "\n",
    "## Warning!\n",
    "This is for educational purposes.  It *is* reasonable to solve this kind of thing with gradient\n",
    "descent, but there are *lots* of tricks that make it \"stable\".  Don't use a gradient descent you've\n",
    "coded yourself in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the problem\n",
    "n1 = np.array([5,-4,8,-10,1,0]).reshape(-1,1)\n",
    "n2 = np.array([7,-2,7,-9,0,-3]).reshape(-1,1)\n",
    "\n",
    "X = np.concatenate( (np.ones( n1.shape ), n1), axis=1 )\n",
    "y = n2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function that iteratively solves\n",
    "# the least squares linear regression problem\n",
    "\n",
    "def linear_regression(Xmatrix, yvector, initialBeta=None, maxIterations=1000, stepSize=0.0001, convergenceThreshold=0.0001):\n",
    "        # nobs is the number of observations\n",
    "        # nparams is the number of parameters\n",
    "    nobs, nparams = X.shape \n",
    "\n",
    "    # X transpose times X\n",
    "    XtX = X.T @ X\n",
    "\n",
    "    if( initialBeta ):\n",
    "        beta = initialBeta # Use the initializer if we have it\n",
    "    else:\n",
    "        beta = np.zeros((nparams,1)) # Initialize at zero \n",
    "\n",
    "    lasterror = np.linalg.norm( y - X @ beta )\n",
    "    error = lasterror\n",
    "    \n",
    "    for i in range(maxIterations):\n",
    "\n",
    "        # the negative of the gradient tells us the direction \n",
    "        # in which to best change the parameters beta\n",
    "        direction = ?\n",
    "\n",
    "        # update beta by taking a small step in the direction we chose\n",
    "        beta = beta + ( stepSize * direction ) \n",
    "\n",
    "        error = np.linalg.norm( y - X @ beta )\n",
    "        if( error > lasterror ):\n",
    "            print('yikes, the error went up!')\n",
    "        elif( lasterror - error < convergenceThreshold ):\n",
    "            break; # the error isn't changing, we can stop early\n",
    "     \n",
    "        lasterror = error\n",
    "\n",
    "    print( 'ran for %d iterations ' % (i+1) )\n",
    "    \n",
    "    return beta, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run our function with our data\n",
    "beta, err = linear_regression( X, y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results like before\n",
    "#\n",
    "# Did we \n",
    "\n",
    "lr_xcoords = np.array([-11,11])\n",
    "lr_ycoords = beta[1] * lr_xcoords + beta[0]\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(n1,n2,s=60)\n",
    "ax.plot( lr_xcoords, lr_ycoords, color='k' )\n",
    "ax.text( -10, 9, 'n2 = %2.2f * n1 + %2.2f'%(beta[1], beta[0]),fontsize=12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
